{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code written and developed by Alexandra Baranowski\n",
    "## University of Cambridge\n",
    "## Prof Alfonso Martinez Arias and Dr Naomi Moris\n",
    "## Copyright 2020 Alexandra Baranowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import tifffile as tiff\n",
    "from scipy import ndimage\n",
    "from scipy import stats\n",
    "from scipy.integrate import trapz\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## location of the 8-bit split channels, per channel\n",
    "\n",
    "data_locn_mask = [\"/Users/Images/8bit Ch1/\", \n",
    "                  \"/Users/Images/8bit Ch2/\", \n",
    "                 \"/Users/Images/8bit Ch3/\", \n",
    "                  \"/Users/Images/8bit Ch4/\"]\n",
    "\n",
    "#print(data_locn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [0,1,2,3]\n",
    "\n",
    "#### Retrieving the images from the location and ordering them in ascending order (N.B. Make sure single digit \n",
    "# numbers are labeled 00, 01, 02 etc otherwise they will not be ordered correctly)\n",
    "\n",
    "files_list0 = []; files_list1 = []; files_list2 = []; files_list3 = []\n",
    "\n",
    "files_list = [files_list0, files_list1, files_list2, files_list3]\n",
    "\n",
    "for i in range(0, len(channels)):\n",
    "    files_list[i].append(glob.glob(data_locn_mask[i]+'*tif'))\n",
    "    files_list[i][0].sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames0 = []; filenames1 = []; filenames2 = []; filenames3 = []\n",
    "\n",
    "filenames = [filenames0, filenames1, filenames2, filenames3]\n",
    "\n",
    "for j in range(0,len(channels)):\n",
    "    for i in files_list[j][0]:\n",
    "        base = os.path.basename(i)\n",
    "        base2 = os.path.splitext(base)[0]\n",
    "        filenames[j].append(os.path.splitext(base2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check that the list names are int the correct order - if the files were not named 00, 01 etc. they will not be\n",
    "\n",
    "#print(files_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denoising\n",
    "\n",
    "#% matplotlib inline \n",
    "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "blurred_0 = []\n",
    "image_copies_0 = []\n",
    "masks_0 = []\n",
    "blurred_masks_0 = []\n",
    "threshold_0 = []\n",
    "\n",
    "for i, v in enumerate(files_list[0][0]):\n",
    "    # read the original image\n",
    "    image_0 = np.array(Image.open(files_list[0][0][i]))\n",
    "\n",
    "    \n",
    "    #Make a copy to prevent distortion of the original, bc all the transformations change the image\n",
    "    image_copy = image_0.copy()\n",
    "    image_copies_0.append(image_copy)\n",
    "    image_copy2 = image_0.copy()\n",
    "\n",
    "    \n",
    "    #Gaussian Blur \n",
    "    blur = cv2.GaussianBlur(image_copy,(25,25),3) # change this depending on the image \n",
    "    blurred_0.append(blur)\n",
    "    \n",
    "    #Set initial threshold \n",
    "    ret, th0 = cv2.threshold(blur, 100, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    threshold_0.append(th0)\n",
    "    mask_inv= cv2.bitwise_not(th0)\n",
    "    \n",
    "    \n",
    "    #blurred mask of the gastruloid - for the fluorescence\n",
    "    blurred_masked_img = cv2.bitwise_and(blur,blur, mask = th0)\n",
    "\n",
    "    # bluured mask of the background - to remove bg noise \n",
    "    #blurred_bg_mask = cv2.bitwise_and(blur,blur, mask = mask_inv)      \n",
    "    blurred_masks_0.append(blurred_masked_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histogram-based determination of the correct threshold for segmentation ###\n",
    "### If the image after Gaussian blur looks bimodal, then use Otsu's ###\n",
    "# Otsu's will set threshold automatically; if not, use historgrams to determine threshold to use #\n",
    "\n",
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html\n",
    "for i, v in enumerate(blurred_0[0:6]): # choose a subset of the images or all of them\n",
    "    \n",
    "    ## finding the range of the grayscale values so we can do the thresholding properly \n",
    "    # https://mmeysenburg.github.io/image-processing/05-creating-histograms/ \n",
    "    hist = cv2.calcHist([v], [0], None, [256], [0, 256])\n",
    "    histogram2=cv2.calcHist(image_copies_0[i], [0], None, [256], [0, 256])\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,3))\n",
    "    \n",
    "    ax[0].plot(histogram2)\n",
    "    ax[0].set_title(\"Grayscale Histogram\") # Before de-noise\n",
    "    ax[0].set_xlabel(\"Grayscale Value\")\n",
    "    ax[0].set_ylabel(\"Pixels\")\n",
    "    ax[1].plot(hist)\n",
    "    ax[1].set_title(\"Grayscale Blurred Histogram\") # After Gaussian Filter\n",
    "    ax[1].set_xlabel(\"Grayscale Value\")\n",
    "    ax[1].set_ylabel(\"Pixels\")\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "save_locn = \"/Users/Image_Output/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify gastruloids\n",
    "\n",
    "from scipy.interpolate import splprep, splev\n",
    "im_out_ = [] # stores the initial floodfilled mask - this will suffice for some gastruloids\n",
    "contours_0rough = [] # only needed if contour smoothing is applied\n",
    "contours_0 = [] # stores the contours for downstream use\n",
    "erosions = [] # stores the mask after erosions to remove debris surrounding gastruloids \n",
    "smoothed_0 = [] # stores the smoothed contours\n",
    "count = 1;\n",
    "\n",
    "for i, v in enumerate(image_copies_0):\n",
    "    blurred_copy = v.copy()\n",
    "    blurred_copy1 = v.copy()\n",
    "    image_copy = v.copy()\n",
    "    v2 = v.copy()\n",
    "    \n",
    "    # Try DoG (imgf) instead of simple Gaussian when Glds have debris around them\n",
    "    blur = cv2.GaussianBlur(image_copy,(25,25),3) \n",
    "    \n",
    "    # The threshold can be kept at 255 bc the Otsu's binarisation algorithm finds the optimal threshold for each image\n",
    "    # this is returned as the ret value \n",
    "    ret, th01 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    mask_inv = cv2.bitwise_not(th0)\n",
    "    th0 = cv2.erode(th01, (5,5) ,iterations =1)\n",
    "    \n",
    "    im_floodfill_0 = th0.copy()\n",
    "    \n",
    "    # Mask used for flood filling; Notice the size needs to be 2 pixels larger than the image.\n",
    "    h, w, = th0.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    # Floodfill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill_0, mask, (0,0), 255)\n",
    "\n",
    "    # Invert floodfilled image\n",
    "    im_floodfill_inv_0 = cv2.bitwise_not(im_floodfill_0)\n",
    "\n",
    "    # Combine the two images to get the foreground\n",
    "    im_out_0 = th0 | im_floodfill_inv_0\n",
    "    im_out_.append(im_out_0)\n",
    "    \n",
    "    #### Cleaning the mask - some gastruloids will NOT require this (e.g., if they are clearly distinguishable from\n",
    "    # background, have smooth edges etc)\n",
    "    kernel = np.ones((25,25),np.uint8)\n",
    "    erosion = cv2.erode(im_out_0, kernel ,iterations =1)\n",
    "    erosions.append(erosion)\n",
    "    \n",
    "    # Finding the contours for each method - this is for comparison; choose the one that best delineates the gastruloids\n",
    "    (contours, _) = cv2.findContours(erosion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    (contours2, _) = cv2.findContours(erosion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    (contours3, _) = cv2.findContours(im_out_0, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    (contours4, _) = cv2.findContours(th0, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contours2 = sorted(contours2, key = cv2.contourArea, reverse = True)[:1]\n",
    "    contours3 = sorted(contours3, key = cv2.contourArea, reverse = True)[:1]\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)[:1]\n",
    "    \n",
    "    if not contours2: \n",
    "        contours2 = np.array([0])\n",
    "    contours_0rough.append(contours2)  \n",
    "    \n",
    "    if not contours3: \n",
    "        contours3 = np.array([0])\n",
    "    smoothed_0.append(contours3)\n",
    "    \n",
    "    # ---- add smoothing code excerpt here, if wanted ------\n",
    "\n",
    "    # -------------------------------------------\n",
    "    \n",
    "    v3 = v.copy()\n",
    "    cv2.drawContours(v3, contours2, -1, (255, 0, 0), 10)     # draw contours over original image\n",
    "    cv2.drawContours(v2, contours3, -1, (255, 0, 0), 10)     # draw contours over original image\n",
    "\n",
    "    #plot it \n",
    "    fig, ax = plt.subplots(1, 6, figsize = (16,5))\n",
    "    ax[0].imshow(th0)\n",
    "    ax[0].set_xlabel(\"Distance / Pixels\")\n",
    "    ax[0].set_ylabel(\"Distance / Pixels\")\n",
    "    ax[0].set_title(\"Before Floodfilling\")\n",
    "    \n",
    "    ax[1].imshow(im_out_0)\n",
    "    ax[1].set_xlabel(\"Distance / Pixels\")\n",
    "    ax[1].set_title(\"After Floodfilling\")\n",
    "    \n",
    "    ax[2].imshow(erosion) \n",
    "    ax[2].set_xlabel(\"Distance / Pixels\")\n",
    "    ax[2].set_title(\"After Floodfilling & Erosion \")\n",
    "    \n",
    "    ax[3].imshow(v)\n",
    "    ax[3].set_xlabel(\"Distance / Pixels\")\n",
    "    ax[3].set_title(\"No Floodfill contour\")\n",
    "    \n",
    "    ax[4].imshow(v2)\n",
    "    ax[4].set_xlabel(\"Distance / Pixels\")\n",
    "    ax[4].set_title(\"Floodfill contour\")\n",
    "\n",
    "    ax[5].imshow(v3)\n",
    "    ax[5].set_xlabel(\"Distance / Pixels\")\n",
    "    ax[5].set_title(\"Floodfill & Erosion contour\")\n",
    "    \n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    save_locn = \"/Users/Images/\"\n",
    "    fig.savefig(save_locn + 'Contours_' + str(count) + '.png')\n",
    "    \n",
    "    count = count+1;\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature extraction\n",
    "\n",
    "areas_0 = []\n",
    "areas0 = [] # this will only be used for QC\n",
    "for i, v in enumerate(erosions):\n",
    "    #find areas\n",
    "    filledareas = cv2.countNonZero(v)\n",
    "    areas0.append(filledareas)\n",
    "\n",
    "\n",
    "for i, c in enumerate(smoothed_0):\n",
    "    if np.size(c)>1:\n",
    "        cnt = c[0]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        areas_0.append(area)\n",
    "    else:\n",
    "        areas_0.append(0)\n",
    "\n",
    "#print(areas_0)\n",
    "#print(areas0)\n",
    "#print(len(areas_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matplotlib.rcParams.update({'figure.max_open_warning': 0})\n",
    "perimeters_0 = []\n",
    "circularity_0 = []\n",
    "boxes_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,c) in enumerate(contours_0rough): # input is the list of contours, depending on which was used above \n",
    "    \n",
    "    if np.size(c)>1:\n",
    "        cnnt = c[0]\n",
    "        # perimeters\n",
    "        perimeters = cv2.arcLength(cnnt,True)\n",
    "        perimeters_0.append(perimeters)\n",
    "        \n",
    "        #circularity\n",
    "        circularity = ((4*np.pi*areas_0[i])/perimeters**2)\n",
    "        circularity_0.append(circularity)\n",
    "\n",
    "        # fitting minimum rotated rectangle\n",
    "        rect = cv2.minAreaRect(cnnt)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        boxes_0.append(box)\n",
    "        \n",
    "    else:\n",
    "        circularity_0.append(0)\n",
    "        boxes_0.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratios_0 = []\n",
    "\n",
    "width = []\n",
    "height = []\n",
    "\n",
    "    \n",
    "## NB: boundingRect doesn't include rotation, but minAreaRect does   \n",
    "for i, v in enumerate(contours_0rough):\n",
    "    cnt = v[0]     \n",
    "    x,z,r = cv2.minAreaRect(cnt) #outputs are center(x,y), (width, height) and rotation\n",
    "    width.append(z[0])\n",
    "    height.append(z[1])    \n",
    "\n",
    "    \n",
    "for i, v in enumerate(width): # normalise the AR so that all values are > 1 so the actual distance can be measured\n",
    "    k = height[i]\n",
    "    #print(k)\n",
    "    if k > v:\n",
    "        aspect_ratios_0.append(np.float(v) / k)\n",
    "    else:\n",
    "        aspect_ratios_0.append(np.float(k) / v)\n",
    "    \n",
    "\n",
    "#print(aspect_ratios_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Area list: 0\n",
      "2) Circularity list: 0\n",
      "3) AR list: 0\n",
      "\n",
      "Check complete - All lists are of same length\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Area list:\", len(areas_0))\n",
    "print(\"2) Circularity list:\", len(circularity_0))\n",
    "print(\"3) AR list:\", len(aspect_ratios_0))\n",
    "\n",
    "if len(areas_0) == len(circularity_0) == len(aspect_ratios_0) :\n",
    "    print(\"\\nCheck complete - All lists are of same length\")\n",
    "else: \n",
    "    print(\"\\nError: all list lengths are not equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations before removing outliers is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nmoris/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/nmoris/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/nmoris/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/nmoris/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/nmoris/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1a7d66e72a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnew_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_area\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Min area is %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Max area is %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Avg area is %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "## QC based on area\n",
    "\n",
    "new_area = []\n",
    "\n",
    "print('Number of observations before removing outliers is %d' %len(areas_0))\n",
    "#print areas_0\n",
    "areas = np.array(areas_0)\n",
    "\n",
    "mean = np.mean(areas, axis=0)\n",
    "sd = np.std(areas, axis=0)\n",
    "bins = 50 \n",
    "new_area = [x for x in areas_0 if (x > mean - 1.5 * sd)]\n",
    "new_area = [x for x in new_area if (x < mean + 1.5 * sd)]\n",
    "\n",
    "print('Min area is %d' %min(new_area))\n",
    "print('Max area is %d' %max(new_area))\n",
    "print('Avg area is %d'%(sum(new_area)/len(new_area)))\n",
    "\n",
    "circ = np.array(circularity_0)\n",
    "\n",
    "mean = np.mean(circ, axis=0)\n",
    "sd = np.std(circ, axis=0)\n",
    "bins = 50 \n",
    "new_circ = [x for x in circularity_0 if (x > mean -1.5 * sd)]\n",
    "new_circ = [x for x in new_circ if (x < mean + 2 * sd)]\n",
    "\n",
    "\n",
    "# print new_area\n",
    "print('Number of observations within the threshold is %d' %len(new_area))\n",
    "print('Number of observations within the threshold is %d' %len(new_circ))\n",
    "\n",
    "# want to identify which position all the outliers are in so we can remove from all the lists \n",
    "outliers_0 = []\n",
    "outliers_circ_0 = []\n",
    "print(\"Outliers are gastruloids at the following indices, with the following areas: \")\n",
    "\n",
    "print(\"Based on area: \")\n",
    "for (num,item) in enumerate(areas_0):\n",
    "    if item not in new_area:\n",
    "        print(num, item)\n",
    "        outliers_0.append(num)\n",
    "print(\"Based on circularity: \")\n",
    "for (num,item) in enumerate(circularity_0):\n",
    "    if item not in new_circ:\n",
    "        print(num, item)\n",
    "        outliers_circ_0.append(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outliers_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-20e8b7449ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal_outliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutliers_0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutliers_circ_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_outliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_outliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal_outliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_outliers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_outliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outliers_0' is not defined"
     ]
    }
   ],
   "source": [
    "total_outliers = outliers_0 + outliers_circ_0 \n",
    "\n",
    "total_outliers = np.unique(total_outliers)\n",
    "total_outliers = total_outliers[::-1]\n",
    "print(total_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'TreatmentConditions': 'ADD VALUES','Date': 'ADD VALUES', 'Hrs Post A': 'ADD VALUES', \n",
    "      'Cell line': 'ADD VALUES', 'Pre treatment': 'ADD VALUES', 'Treatment': 'ADD VALUES', 'Cell number': 'ADD VALUES',\n",
    "     'Area Ch0': areas_0, 'Circularity': circularity_0, 'Min rot rect Ch0': boxes_0,'AR Ch0': aspect_ratios_0\n",
    "}  \n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "#df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Images/NameOfFile.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7b81fe94134e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/Images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'NameOfFile.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         )\n\u001b[0;32m-> 3228\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Images/NameOfFile.csv'"
     ]
    }
   ],
   "source": [
    "path = '/Users/Images/'\n",
    "\n",
    "df.to_csv(path+'NameOfFile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
